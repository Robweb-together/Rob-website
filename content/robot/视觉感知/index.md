---
title: 视觉感知
date: 2024-01-01

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# image:
#   caption: '机器视觉技术'
#   focal_point: ""
#   preview_only: false

---

视觉感知是机器人感知和理解环境的关键技术，致力于通过视觉传感器获取环境信息，为机器人的自主导航、精确操作和智能决策提供支撑。我们的研究涵盖了从基础理论到技术应用的多个层面，形成了系统的视觉感知技术体系。

<!--more-->

## 研究概述

视觉感知研究聚焦于开发鲁棒、高效的视觉感知算法，使机器人能够在复杂、动态的环境中实现精确的环境感知和目标识别。我们的研究团队在多个关键技术上取得了重要突破，特别是在SLAM、视觉伺服、环境感知等方面形成了独特的技术优势。

## 核心研究方向

### 1. 移动机器人SLAM技术

**研究背景**

同步定位与地图构建（SLAM）是移动机器人自主导航的基础技术，在低纹理、动态变化的环境中面临重大挑战。传统的SLAM方法在激光雷达退化环境和纹理缺失场景中容易失效，导致定位精度下降和地图构建失败。特别是在工业环境、地下空间、长走廊等场景中，单一传感器往往无法提供足够的特征信息。多传感器融合SLAM技术通过整合激光雷达、相机、惯性测量单元等多种传感器的优势，实现互补增强，为移动机器人在复杂环境中的稳定导航提供了技术保障。

**研究内容**

{{< figure src="mobile-SLAM.jpg" title="移动机器人SLAM【章】" >}}

- 开发了LVIO-Fusion多传感器融合SLAM系统，实现激光雷达-视觉-惯性紧耦合
- 设计了适应退化环境的定位算法，处理激光雷达退化场景
- 实现了实时地图构建和更新，采用动态体素映射方法
- 建立了鲁棒的状态估计方法，基于粗到细的状态估计策略
- 开发了在线光度标定技术，获取真实辐射信息

**部分成果**

- **Zhang Hongkai, et al.** "[LVIO-Fusion:Tightly-Coupled LiDAR-Visual-Inertial Odometry and Mapping in Degenerate Environments](/publication/zhang2024LVIO-Fusion/)", *IEEE Robotics and Automation Letters*, 2024
- **Guo Dianzhen, et al.** "[Visualized Small-size Pipeline Model Building Using Multilink-articulated Wheeled In-pipe Inspection Robot](/publication/guo2021visualized/)", *RCAR*, 2021

<!-- 移动机器人SLAM系统图片 -->

### 2. 内容识别与理解

**研究背景**

机器人在执行操作任务时需要准确感知操作环境，包括目标物体的位置、姿态、形状等信息。传统的视觉方法在复杂环境中面临光照变化、遮挡、噪声等挑战，难以实现稳定可靠的目标识别。特别是在工业检测、质量评估、环境建模等应用场景中，需要处理大量、多样化的视觉数据，对算法的鲁棒性和实时性提出了极高要求。基于点云处理和多模态传感器融合的环境感知技术，通过整合多种传感器的信息，实现对复杂场景的全面理解和准确识别。

**研究内容**

{{< figure src="object-recognition.jpg" title="内容识别与理解【胡】" >}}

- 开发了基于点云处理的物体位姿识别技术，实现高精度位姿检测
- 设计了多模态传感器融合感知系统，整合多种传感器信息
- 实现了复杂场景下的目标检测与跟踪，适应动态环境
- 建立了环境建模与理解方法，支持三维环境重建
- 开发了可视化管道模型构建技术，用于管道检测应用

**部分成果**

- **Guo Dianzhen, et al.** "[Visualized Small-size Pipeline Model Building Using Multilink-articulated Wheeled In-pipe Inspection Robot](/publication/guo2021visualized/)", *RCAR*, 2021

<!-- 机器人操作环境感知系统图片 -->

### 3. 视觉伺服控制技术

**研究背景**

视觉伺服控制是机器人实现精确操作的关键技术，需要在复杂环境中实现稳定、精确的视觉反馈控制。传统的视觉伺服方法在污染环境、光照变化、目标状态不确定等条件下往往表现不佳，导致控制精度下降和系统不稳定。特别是在工业应用和特种作业中，如TBM刀具更换、精密装配等场景，对视觉伺服的鲁棒性和精度提出了极高要求。基于网格方向误差映射的视觉伺服技术通过创新的控制策略和鲁棒算法设计，为机器人在恶劣环境中的精确操作提供了有效解决方案。

**研究内容**

{{< figure src="visual-servo.jpg" title="视觉伺服控制技术" >}}

- 开发了基于网格方向误差映射的视觉伺服方法，提高控制鲁棒性
- 设计了适应污染环境的鲁棒视觉控制器，处理环境干扰
- 实现了TBM刀具更换的视觉伺服系统，支持现场应用
- 建立了视觉伺服控制理论体系，包括交互矩阵设计
- 开发了直接恒定的交互矩阵映射方法，简化控制计算

**部分成果**

- **Yang Qiang, et al.** "[Visual Servoing With Grid‐Based Directional Error Mapping for Robotic TBM Disc Cutter Replacement](/publication/yang2025visual/)", *Journal of Field Robotics*, 2025

<!-- 视觉伺服控制系统图片 -->

## 研究意义与发展

视觉感知研究在机器人技术发展中具有重要的理论意义和实用价值。通过多传感器融合技术和退化环境适应算法的开发，我们建立了适应复杂环境的机器人视觉感知理论体系。实时处理能力和鲁棒性设计的引入为机器人系统在动态环境中的稳定运行提供了技术保障，而模块化视觉软件框架的建立为视觉技术的工程化应用提供了系统性支撑。

目前的研究成果在工业自动化、移动机器人、服务机器人、医疗康复、农业自动化等领域展现出良好的应用潜力。特别是在质量检测、自主导航、人机交互、手术导航等场景中，我们的视觉感知技术为实现精确、可靠的环境感知和目标识别提供了有效方案。

未来研究将重点关注深度学习集成、边缘计算、云端协同、多机器人视觉、人机视觉交互等前沿技术，为机器人视觉感知技术的进一步发展提供理论和技术支撑。
